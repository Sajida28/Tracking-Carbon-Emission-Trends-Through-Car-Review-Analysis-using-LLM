{"cells":[{"source":"# **Title: Tracking Carbon Emission Trends Through Car Review Analysis using LLM**\n","metadata":{},"id":"9aabafca-8129-4943-b865-d5e897637253","cell_type":"markdown"},{"source":"**Project Description**\n\n- Conducted carbon emission tracking within the entirety of the project's code and assessed its trend over time.\n- Used a pre-trained LLM to classify the sentiment of the five car reviews in the car_reviews.csv dataset, and evaluated the classification accuracy and F1 score of predictions.\n- Extracted and passed the first two sentences of the first review in the dataset to an English-to-Spanish translation LLM for Spanish customers. \n- Calculated the BLEU score to assess translation quality, using the content in reference_translations.txt as references.\n- Loaded an extractive QA LLM such as \"deepset/minilm-uncased-squad2\" to formulate the question \"What did he like about the brand?\" and obtain an answer from 2nd Review to emphasize on brand aspects.\n- Summarized the last review in the dataset, into approximately 50-55 tokens long. ","metadata":{},"id":"012c6cfc","cell_type":"markdown"},{"source":"!pip install transformers\n!pip install datasets\n!pip install evaluate\n!pip install codecarbon\nfrom transformers import logging\nlogging.set_verbosity(logging.WARNING)","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":28555,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1714661847833,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install transformers\n!pip install datasets\n!pip install evaluate\n!pip install codecarbon\nfrom transformers import logging\nlogging.set_verbosity(logging.WARNING)","outputsMetadata":{"0":{"height":553,"type":"stream"}}},"id":"5325a4c0-ceb3-4b66-acd2-5eadcefe3a63","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.29.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.23.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.8.17)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.10.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.23.2)\nRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (7.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.5.1)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.0)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.13)\nRequirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2022.7.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.10.15)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2019.11.28)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from responses<0.19->datasets) (1.14.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\nDefaulting to user installation because normal site-packages is not writeable\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.10.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.23.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.5.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.5.1)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.0)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.3.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.13)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2022.7.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\nRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (7.0.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.1)\nRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (0.10.15)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2019.11.28)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.14.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\n\u001b[33m  WARNING: The script evaluate-cli is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed evaluate-0.4.2\nDefaulting to user installation because normal site-packages is not writeable\nCollecting codecarbon\n  Downloading codecarbon-2.3.5-py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: arrow in /usr/local/lib/python3.8/dist-packages (from codecarbon) (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from codecarbon) (1.5.1)\nCollecting pynvml (from codecarbon)\n  Downloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from codecarbon) (2.31.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from codecarbon) (5.9.4)\nCollecting py-cpuinfo (from codecarbon)\n  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\nCollecting rapidfuzz (from codecarbon)\n  Downloading rapidfuzz-3.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from codecarbon) (8.1.3)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from codecarbon) (0.14.1)\nRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from arrow->codecarbon) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->codecarbon) (2022.7)\nRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas->codecarbon) (1.23.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->codecarbon) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->codecarbon) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->codecarbon) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->codecarbon) (2019.11.28)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.14.0)\nDownloading codecarbon-2.3.5-py3-none-any.whl (174 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.6/174.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\nDownloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: py-cpuinfo, rapidfuzz, pynvml, codecarbon\n\u001b[33m  WARNING: The script cpuinfo is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m  WARNING: The scripts carbonboard and codecarbon are installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed codecarbon-2.3.5 py-cpuinfo-9.0.0 pynvml-11.5.0 rapidfuzz-3.8.1\n"}]},{"source":"import pandas as pd\nimport torch\nimport numpy as np\nfrom codecarbon import EmissionsTracker","metadata":{"executionCancelledAt":null,"executionTime":950,"lastExecutedAt":1714661848785,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport torch\nimport numpy as np\nfrom codecarbon import EmissionsTracker"},"id":"6c3a3bf7-8675-4fdf-8580-0c69b58f471e","cell_type":"code","execution_count":2,"outputs":[]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Load the car reviews dataset\nfile_path = \"data/car_reviews.csv\"\ndf = pd.read_csv(file_path, delimiter=\";\")\n\n# Put the car reviews and their associated sentiment labels in two lists\nreviews = df['Review'].tolist()\nreal_labels = df['Class'].tolist()\n\nemissions = tracker.stop()  \n","metadata":{"executionCancelledAt":null,"executionTime":4578,"lastExecutedAt":1714661853364,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Load the car reviews dataset\nfile_path = \"data/car_reviews.csv\"\ndf = pd.read_csv(file_path, delimiter=\";\")\n\n# Put the car reviews and their associated sentiment labels in two lists\nreviews = df['Review'].tolist()\nreal_labels = df['Class'].tolist()\n\nemissions = tracker.stop()  \n","outputsMetadata":{"0":{"height":395,"type":"stream"}}},"id":"6061f417-de48-4faa-af3c-18c1275a3830","cell_type":"code","execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 14:57:28] [setup] RAM Tracking...\n[codecarbon INFO @ 14:57:28] [setup] GPU Tracking...\n[codecarbon INFO @ 14:57:28] No GPU found.\n[codecarbon INFO @ 14:57:28] [setup] CPU Tracking...\n[codecarbon WARNING @ 14:57:28] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 14:57:29] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 14:57:29] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 14:57:29] >>> Tracker's metadata:\n[codecarbon INFO @ 14:57:29]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 14:57:29]   Python version: 3.8.10\n[codecarbon INFO @ 14:57:29]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 14:57:29]   Available RAM : 61.460 GB\n[codecarbon INFO @ 14:57:29]   CPU count: 16\n[codecarbon INFO @ 14:57:29]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 14:57:29]   GPU count: None\n[codecarbon INFO @ 14:57:29]   GPU model: None\n[codecarbon INFO @ 14:57:33] Energy consumed for RAM : 0.000000 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 14:57:33] Energy consumed for all CPUs : 0.000000 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 14:57:33] 0.000000 kWh of electricity used since the beginning.\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n\n# Load a sentiment analysis LLM into a pipeline\nfrom transformers import pipeline\n# The model used is 'distilbert-base-uncased-finetuned-sst-2-english':\n    # 'distilbert-base-uncased' refers to a distilled (simplified and faster) version of BERT that is case-insensitive.\n    # 'finetuned-sst-2-english' indicates the model is fine-tuned on the SST-2 dataset, a benchmark for sentiment analysis,\n    # specifically trained to detect sentiments in English text.\nclassifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n\nemissions = tracker.stop() ","metadata":{"executionCancelledAt":null,"executionTime":5237,"lastExecutedAt":1714662287676,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n\n# Load a sentiment analysis LLM into a pipeline\nfrom transformers import pipeline\n# The model used is 'distilbert-base-uncased-finetuned-sst-2-english':\n    # 'distilbert-base-uncased' refers to a distilled (simplified and faster) version of BERT that is case-insensitive.\n    # 'finetuned-sst-2-english' indicates the model is fine-tuned on the SST-2 dataset, a benchmark for sentiment analysis,\n    # specifically trained to detect sentiments in English text.\nclassifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n\nemissions = tracker.stop() ","outputsMetadata":{"0":{"height":395,"type":"stream"},"4":{"height":101,"type":"stream"},"5":{"height":143,"type":"stream"}}},"id":"ac175aa1-1090-402e-bb42-1f406b2c607e","cell_type":"code","execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:04:42] [setup] RAM Tracking...\n[codecarbon INFO @ 15:04:42] [setup] GPU Tracking...\n[codecarbon INFO @ 15:04:42] No GPU found.\n[codecarbon INFO @ 15:04:42] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:04:42] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:04:43] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:04:43] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:04:43] >>> Tracker's metadata:\n[codecarbon INFO @ 15:04:43]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:04:43]   Python version: 3.8.10\n[codecarbon INFO @ 15:04:43]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:04:43]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:04:43]   CPU count: 16\n[codecarbon INFO @ 15:04:43]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:04:43]   GPU count: None\n[codecarbon INFO @ 15:04:43]   GPU model: None\n[codecarbon INFO @ 15:04:47] Energy consumed for RAM : 0.000005 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:04:47] Energy consumed for all CPUs : 0.000010 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:04:47] 0.000015 kWh of electricity used since the beginning.\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Perform inference on the car reviews and display prediction results\npredicted_labels = classifier(reviews)\nfor review, prediction, label in zip(reviews, predicted_labels, real_labels):\n    print(f\"Review: {review}\\nActual Sentiment: {label}\\nPredicted Sentiment: {prediction['label']} (Confidence: {prediction['score']:.4f})\\n\")\n\nemissions = tracker.stop() ","metadata":{"executionCancelledAt":null,"executionTime":7807,"lastExecutedAt":1714662298306,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Perform inference on the car reviews and display prediction results\npredicted_labels = classifier(reviews)\nfor review, prediction, label in zip(reviews, predicted_labels, real_labels):\n    print(f\"Review: {review}\\nActual Sentiment: {label}\\nPredicted Sentiment: {prediction['label']} (Confidence: {prediction['score']:.4f})\\n\")\n\nemissions = tracker.stop() ","outputsMetadata":{"0":{"height":416,"type":"stream"},"1":{"height":475,"type":"stream"}}},"id":"e52dfcd7-f4c3-4071-a7ba-64a3d4819949","cell_type":"code","execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:04:50] [setup] RAM Tracking...\n[codecarbon INFO @ 15:04:50] [setup] GPU Tracking...\n[codecarbon INFO @ 15:04:50] No GPU found.\n[codecarbon INFO @ 15:04:50] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:04:50] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:04:51] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:04:51] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:04:51] >>> Tracker's metadata:\n[codecarbon INFO @ 15:04:51]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:04:51]   Python version: 3.8.10\n[codecarbon INFO @ 15:04:51]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:04:51]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:04:51]   CPU count: 16\n[codecarbon INFO @ 15:04:51]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:04:51]   GPU count: None\n[codecarbon INFO @ 15:04:51]   GPU model: None\n[codecarbon INFO @ 15:04:58] Energy consumed for RAM : 0.000022 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:04:58] Energy consumed for all CPUs : 0.000040 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:04:58] 0.000062 kWh of electricity used since the beginning.\n"},{"output_type":"stream","name":"stdout","text":"Review: I am very satisfied with my 2014 Nissan NV SL. I use this van for my business deliveries and personal use. Camping, road trips, etc. We dont have any children so I store most of the seats in my warehouse. I wanted the passenger van for the rear air conditioning. We drove our van from Florida to California for a Cross Country trip in 2014. We averaged about 18 mpg. We drove thru a lot of rain and It was a very comfortable and stable vehicle. The V8 Nissan Titan engine is a 500k mile engine. It has been tested many times by delivery and trucking companies. This is why Nissan gives you a 5 year or 100k mile bumper to bumper warranty. Many people are scared about driving this van because of its size. But with front and rear sonar sensors, large mirrors and the back up camera. It is easy to drive. The front and rear sensors also monitor the front and rear sides of the bumpers making it easier to park close to objects. Our Nissan NV is a Tow Monster. It pulls our 5000 pound travel trailer like its not even there. I have plenty of power to pass a vehicle if needed. The 5.6 liter engine produces 317 hp. I have owned Chevy and Ford vans and there were not very comfortable and had little cockpit room. The Nissan NV is the only vehicle made that has the engine forward like a pick up truck giving the driver plenty of room and comfort in the cockpit area. I dont have any negatives to say about my NV. This is a wide vehicle. The only modification I would like to see from Nissan is for them to add amber side mirror marker lights.BTW. I now own a 2016 Nissan NVP SL. Love it.\nActual Sentiment: POSITIVE\nPredicted Sentiment: POSITIVE (Confidence: 0.9294)\n\nReview: The car is fine. It's a bit loud and not very powerful. On one hand, compared to its peers, the interior is well-built. The transmission failed a few years ago, and the dealer replaced it under warranty with no issues. Now, about 60k miles later, the transmission is failing again. It sounds like a truck, and the issues are well-documented. The dealer tells me it is normal, refusing to do anything to resolve the issue. After owning the car for 4 years, there are many other vehicles I would purchase over this one. Initially, I really liked what the brand is about: ride quality, reliability, etc. But I will not purchase another one. Despite these concerns, I must say, the level of comfort in the car has always been satisfactory, but not worth the rest of issues found.\nActual Sentiment: NEGATIVE\nPredicted Sentiment: POSITIVE (Confidence: 0.8654)\n\nReview: My first foreign car. Love it, I would buy another.\nActual Sentiment: POSITIVE\nPredicted Sentiment: POSITIVE (Confidence: 0.9995)\n\nReview: I've come across numerous reviews praising the Rogue, and I genuinely feel like I might be missing something. It's only been a week since I got the car, and I am genuinely disappointed. I truly wish I could return it. My main concern revolves around what I see as a significant design flaw (which I believe also exists in the Murano, though that wasn't much better and considerably pricier). The rear windshield is just too small. The headrests in the back seat obstruct the sides of the rearview window. This \"Crossover\" feels more like a cheaply made compact car. My other vehicle is a Sonata, and it provides a significantly quieter and smoother ride. I did not anticipate this car to ride so roughly; my 2006 Pathfinder had a smoother ride! I would rate this car a 5 all around.\nActual Sentiment: NEGATIVE\nPredicted Sentiment: NEGATIVE (Confidence: 0.9935)\n\nReview: I've been dreaming of owning an SUV for quite a while, but I've been driving cars that were already paid for during an extended period. I ultimately made the decision to transition to a brand-new car, which, of course, involved taking on new payments. However, given that I don't drive extensively, I was inclined to avoid a substantial financial commitment. The Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment; the financial arrangement is quite reasonable. Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more. I am VERY satisfied overall. I find myself needing to exercise extra caution when making lane changes, particularly owing to the blind spots resulting from the small side windows situated towards the rear of the vehicle. To address this concern, I am actively engaged in making adjustments to my mirrors and consciously reducing the frequency of lane changes. The engine delivers strong performance, and the ride is really smooth.\nActual Sentiment: POSITIVE\nPredicted Sentiment: POSITIVE (Confidence: 0.9987)\n\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Load accuracy and F1 score metrics    \nimport evaluate\naccuracy = evaluate.load(\"accuracy\")\nf1 = evaluate.load(\"f1\") # We use f1 score because it is useful for uneven classes and it considers both precision and recal\nemissions = tracker.stop() ","metadata":{"executionCancelledAt":null,"executionTime":4568,"lastExecutedAt":1714662302875,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Load accuracy and F1 score metrics    \nimport evaluate\naccuracy = evaluate.load(\"accuracy\")\nf1 = evaluate.load(\"f1\") # We use f1 score because it is useful for uneven classes and it considers both precision and recal\nemissions = tracker.stop() ","outputsMetadata":{"0":{"height":458,"type":"stream"},"3":{"height":80,"type":"stream"}}},"id":"40f51e3b-355d-428b-96d0-21dee1973d3c","cell_type":"code","execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:04:58] [setup] RAM Tracking...\n[codecarbon INFO @ 15:04:58] [setup] GPU Tracking...\n[codecarbon INFO @ 15:04:58] No GPU found.\n[codecarbon INFO @ 15:04:58] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:04:58] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:04:59] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:04:59] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:04:59] >>> Tracker's metadata:\n[codecarbon INFO @ 15:04:59]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:04:59]   Python version: 3.8.10\n[codecarbon INFO @ 15:04:59]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:04:59]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:04:59]   CPU count: 16\n[codecarbon INFO @ 15:04:59]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:04:59]   GPU count: None\n[codecarbon INFO @ 15:04:59]   GPU model: None\n[codecarbon INFO @ 15:05:02] Energy consumed for RAM : 0.000001 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:05:02] Energy consumed for all CPUs : 0.000003 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:05:02] 0.000004 kWh of electricity used since the beginning.\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Map categorical sentiment labels into integer labels\n\nreferences = [1 if label == \"POSITIVE\" else 0 for label in real_labels]\npredictions = [1 if label['label'] == \"POSITIVE\" else 0 for label in predicted_labels]\n\nemissions = tracker.stop() ","metadata":{"executionCancelledAt":null,"executionTime":4358,"lastExecutedAt":1714662309286,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Map categorical sentiment labels into integer labels\n\nreferences = [1 if label == \"POSITIVE\" else 0 for label in real_labels]\npredictions = [1 if label['label'] == \"POSITIVE\" else 0 for label in predicted_labels]\n\nemissions = tracker.stop() ","outputsMetadata":{"0":{"height":458,"type":"stream"}}},"id":"e823bedf-51cc-4e23-8468-b6fe0aa6d4e3","cell_type":"code","execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:05:04] [setup] RAM Tracking...\n[codecarbon INFO @ 15:05:04] [setup] GPU Tracking...\n[codecarbon INFO @ 15:05:04] No GPU found.\n[codecarbon INFO @ 15:05:04] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:05:04] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:05:06] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:05:06] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:06] >>> Tracker's metadata:\n[codecarbon INFO @ 15:05:06]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:05:06]   Python version: 3.8.10\n[codecarbon INFO @ 15:05:06]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:05:06]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:05:06]   CPU count: 16\n[codecarbon INFO @ 15:05:06]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:06]   GPU count: None\n[codecarbon INFO @ 15:05:06]   GPU model: None\n[codecarbon INFO @ 15:05:09] Energy consumed for RAM : 0.000000 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:05:09] Energy consumed for all CPUs : 0.000000 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:05:09] 0.000000 kWh of electricity used since the beginning.\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Calculate accuracy and F1 score\naccuracy_result_dict = accuracy.compute(references=references, predictions=predictions)\naccuracy_result = accuracy_result_dict['accuracy']\nf1_result_dict = f1.compute(references=references, predictions=predictions)\nf1_result = f1_result_dict['f1']\nprint(f\"Accuracy: {accuracy_result}\")\nprint(f\"F1 result: {f1_result}\")\nemissions = tracker.stop() \n\n","metadata":{"executionCancelledAt":null,"executionTime":4401,"lastExecutedAt":1714662315867,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Calculate accuracy and F1 score\naccuracy_result_dict = accuracy.compute(references=references, predictions=predictions)\naccuracy_result = accuracy_result_dict['accuracy']\nf1_result_dict = f1.compute(references=references, predictions=predictions)\nf1_result = f1_result_dict['f1']\nprint(f\"Accuracy: {accuracy_result}\")\nprint(f\"F1 result: {f1_result}\")\nemissions = tracker.stop() \n\n","outputsMetadata":{"0":{"height":458,"type":"stream"},"1":{"height":59,"type":"stream"}}},"id":"4c911e81-73ab-4ee6-9d3a-952899945b12","cell_type":"code","execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:05:11] [setup] RAM Tracking...\n[codecarbon INFO @ 15:05:11] [setup] GPU Tracking...\n[codecarbon INFO @ 15:05:11] No GPU found.\n[codecarbon INFO @ 15:05:11] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:05:11] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:05:12] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:05:12] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:12] >>> Tracker's metadata:\n[codecarbon INFO @ 15:05:12]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:05:12]   Python version: 3.8.10\n[codecarbon INFO @ 15:05:12]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:05:12]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:05:12]   CPU count: 16\n[codecarbon INFO @ 15:05:12]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:12]   GPU count: None\n[codecarbon INFO @ 15:05:12]   GPU model: None\n[codecarbon INFO @ 15:05:15] Energy consumed for RAM : 0.000000 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:05:15] Energy consumed for all CPUs : 0.000000 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:05:15] 0.000000 kWh of electricity used since the beginning.\n"},{"output_type":"stream","name":"stdout","text":"Accuracy: 0.8\nF1 result: 0.8571428571428571\n"}]},{"source":"Our sentiment analysis model, based on DistilBERT fine-tuned on SST-2, achieved an accuracy of 80% and an F1 score of approximately 0.857, demonstrating its effectiveness and accuracy in identifying the sentiment of car reviews. These results indicate that the model is reliable in classifying sentiments as either positive or negative, making it a valuable tool for analyzing customer feedback.\n\n\n\n\n\n\n","metadata":{},"id":"850e814a-f563-40b3-bf22-5a65f71be346","cell_type":"markdown"},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n\n# Load translation LLM into a pipeline and translate car review\nfirst_review = reviews[0] #Extract the first review\ntranslator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\") \n\n#This model utilizes the Transformer architecture, which is highly effective for translation tasks because it can handle long-range dependencies in text, making it suitable for complex sentence structures and idiomatic expressions. Using this model ensures that translations between English and Spanish are fluent and contextually appropriate.\n\ntranslated_review = translator(first_review, max_length=27)[0]['translation_text']\nprint(f\"Model translation:\\n{translated_review}\")\n\nemissions = tracker.stop() ","metadata":{"executionCancelledAt":null,"executionTime":10456,"lastExecutedAt":1714662327403,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n\n# Load translation LLM into a pipeline and translate car review\nfirst_review = reviews[0] #Extract the first review\ntranslator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\") \n\n#This model utilizes the Transformer architecture, which is highly effective for translation tasks because it can handle long-range dependencies in text, making it suitable for complex sentence structures and idiomatic expressions. Using this model ensures that translations between English and Spanish are fluent and contextually appropriate.\n\ntranslated_review = translator(first_review, max_length=27)[0]['translation_text']\nprint(f\"Model translation:\\n{translated_review}\")\n\nemissions = tracker.stop() ","outputsMetadata":{"0":{"height":395,"type":"stream"},"1":{"height":101,"type":"stream"},"7":{"height":59,"type":"stream"},"8":{"height":122,"type":"stream"},"9":{"height":80,"type":"stream"}}},"id":"e253f7f1-c188-4db3-86b8-d5b04a9c4575","cell_type":"code","execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:05:16] [setup] RAM Tracking...\n[codecarbon INFO @ 15:05:16] [setup] GPU Tracking...\n[codecarbon INFO @ 15:05:16] No GPU found.\n[codecarbon INFO @ 15:05:16] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:05:16] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:05:18] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:05:18] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:18] >>> Tracker's metadata:\n[codecarbon INFO @ 15:05:18]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:05:18]   Python version: 3.8.10\n[codecarbon INFO @ 15:05:18]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:05:18]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:05:18]   CPU count: 16\n[codecarbon INFO @ 15:05:18]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:18]   GPU count: None\n[codecarbon INFO @ 15:05:18]   GPU model: None\nYour input_length: 365 is bigger than 0.9 * max_length: 27. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n[codecarbon INFO @ 15:05:27] Energy consumed for RAM : 0.000039 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:05:27] Energy consumed for all CPUs : 0.000072 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:05:27] 0.000110 kWh of electricity used since the beginning.\n"},{"output_type":"stream","name":"stdout","text":"Model translation:\nEstoy muy satisfecho con mi 2014 Nissan NV SL. Uso esta furgoneta para mis entregas de negocios y uso personal.\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Load reference translations from file\nwith open(\"data/reference_translations.txt\", 'r') as file:\n    lines = file.readlines()\nreferences = [line.strip() for line in lines] #This strip function is used to clean up the lines, removing any leading and trailing whitespace, including the newline characters, making the data cleaner and easier to use in further processing.\nprint(f\"Spanish translation references:\\n{references}\")\nemissions = tracker.stop() \n","metadata":{"executionCancelledAt":null,"executionTime":4343,"lastExecutedAt":1714662331746,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Load reference translations from file\nwith open(\"data/reference_translations.txt\", 'r') as file:\n    lines = file.readlines()\nreferences = [line.strip() for line in lines] #This strip function is used to clean up the lines, removing any leading and trailing whitespace, including the newline characters, making the data cleaner and easier to use in further processing.\nprint(f\"Spanish translation references:\\n{references}\")\nemissions = tracker.stop() \n","outputsMetadata":{"0":{"height":395,"type":"stream"},"1":{"height":101,"type":"stream"}}},"id":"4d5c206f-1fbc-4a38-bd68-9fead9e9cc58","cell_type":"code","execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:05:27] [setup] RAM Tracking...\n[codecarbon INFO @ 15:05:27] [setup] GPU Tracking...\n[codecarbon INFO @ 15:05:27] No GPU found.\n[codecarbon INFO @ 15:05:27] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:05:27] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:05:28] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:05:28] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:28] >>> Tracker's metadata:\n[codecarbon INFO @ 15:05:28]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:05:28]   Python version: 3.8.10\n[codecarbon INFO @ 15:05:28]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:05:28]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:05:28]   CPU count: 16\n[codecarbon INFO @ 15:05:28]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:28]   GPU count: None\n[codecarbon INFO @ 15:05:28]   GPU model: None\n[codecarbon INFO @ 15:05:31] Energy consumed for RAM : 0.000000 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:05:31] Energy consumed for all CPUs : 0.000000 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:05:31] 0.000000 kWh of electricity used since the beginning.\n"},{"output_type":"stream","name":"stdout","text":"Spanish translation references:\n['Estoy muy satisfecho con mi Nissan NV SL 2014. Utilizo esta camioneta para mis entregas comerciales y uso personal.', 'Estoy muy satisfecho con mi Nissan NV SL 2014. Uso esta furgoneta para mis entregas comerciales y uso personal.']\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n#BLEU (Bilingual Evaluation Understudy) is commonly used to evaluate the quality of machine-translated text against a set of reference translations.\nbleu = evaluate.load(\"bleu\")\n# Load and calculate BLEU score metric\nbleu = evaluate.load(\"bleu\")\nbleu_score = bleu.compute(predictions=[translated_review], references=[references])\nprint(bleu_score['bleu'])\n\n\nemissions = tracker.stop() ","metadata":{"executionCancelledAt":null,"executionTime":4880,"lastExecutedAt":1714662336626,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n#BLEU (Bilingual Evaluation Understudy) is commonly used to evaluate the quality of machine-translated text against a set of reference translations.\nbleu = evaluate.load(\"bleu\")\n# Load and calculate BLEU score metric\nbleu = evaluate.load(\"bleu\")\nbleu_score = bleu.compute(predictions=[translated_review], references=[references])\nprint(bleu_score['bleu'])\n\n\nemissions = tracker.stop() ","outputsMetadata":{"0":{"height":395,"type":"stream"},"1":{"height":38,"type":"stream"},"3":{"height":38,"type":"stream"},"4":{"height":80,"type":"stream"},"5":{"height":38,"type":"stream"}}},"id":"57344c52-c6d7-4fc7-99fc-b2db1e791ec8","cell_type":"code","execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:05:31] [setup] RAM Tracking...\n[codecarbon INFO @ 15:05:31] [setup] GPU Tracking...\n[codecarbon INFO @ 15:05:31] No GPU found.\n[codecarbon INFO @ 15:05:31] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:05:31] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:05:32] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:05:32] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:32] >>> Tracker's metadata:\n[codecarbon INFO @ 15:05:32]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:05:32]   Python version: 3.8.10\n[codecarbon INFO @ 15:05:32]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:05:32]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:05:32]   CPU count: 16\n[codecarbon INFO @ 15:05:32]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:32]   GPU count: None\n[codecarbon INFO @ 15:05:32]   GPU model: None\n[codecarbon INFO @ 15:05:36] Energy consumed for RAM : 0.000003 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:05:36] Energy consumed for all CPUs : 0.000006 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:05:36] 0.000010 kWh of electricity used since the beginning.\n"},{"output_type":"stream","name":"stdout","text":"0.6022774485691839\n"}]},{"source":"BLEU score ranges from 0 to 1 where 0.6023(60.23%) suggests that our translation has a moderate to good alignment with a refernce translations. It's not perfect but it conveys original meaning correctly but there maybe some difference in word coice , grammar or stylistic elements etc.","metadata":{},"id":"08d656ec-ba73-4710-b947-63367d6bc9d9","cell_type":"markdown"},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n\n# Import auto classes (optional: can be solved via pipelines too)\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForQuestionAnswering\nemissions = tracker.stop() \n","metadata":{"executionCancelledAt":null,"executionTime":4363,"lastExecutedAt":1714662340989,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n\n# Import auto classes (optional: can be solved via pipelines too)\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForQuestionAnswering\nemissions = tracker.stop() \n","outputsMetadata":{"0":{"height":458,"type":"stream"}}},"id":"7bad07fa-1574-473c-a2bc-c8adc95a96f4","cell_type":"code","execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:05:36] [setup] RAM Tracking...\n[codecarbon INFO @ 15:05:36] [setup] GPU Tracking...\n[codecarbon INFO @ 15:05:36] No GPU found.\n[codecarbon INFO @ 15:05:36] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:05:36] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:05:37] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:05:37] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:37] >>> Tracker's metadata:\n[codecarbon INFO @ 15:05:37]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:05:37]   Python version: 3.8.10\n[codecarbon INFO @ 15:05:37]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:05:37]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:05:37]   CPU count: 16\n[codecarbon INFO @ 15:05:37]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:37]   GPU count: None\n[codecarbon INFO @ 15:05:37]   GPU model: None\n[codecarbon INFO @ 15:05:40] Energy consumed for RAM : 0.000000 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:05:40] Energy consumed for all CPUs : 0.000000 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:05:40] 0.000000 kWh of electricity used since the beginning.\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n\n# Instantiate model and tokenizer (For breaking down the text into tokens that the model can process)\n\nmodel_ckp = \"deepset/minilm-uncased-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckp) \n\n# Load the question answering model from the same checkpoint. This model is specifically designed for the task of answering questions based on a given text context.\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_ckp)\n\nemissions = tracker.stop() ","metadata":{"executionCancelledAt":null,"executionTime":5752,"lastExecutedAt":1714662353640,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n\n# Instantiate model and tokenizer (For breaking down the text into tokens that the model can process)\n\nmodel_ckp = \"deepset/minilm-uncased-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckp) \n\n# Load the question answering model from the same checkpoint. This model is specifically designed for the task of answering questions based on a given text context.\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_ckp)\n\nemissions = tracker.stop() ","outputsMetadata":{"0":{"height":395,"type":"stream"},"6":{"height":80,"type":"stream"}}},"id":"5311393f-d20b-49ea-aa16-4e02327b2b40","cell_type":"code","execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:05:47] [setup] RAM Tracking...\n[codecarbon INFO @ 15:05:47] [setup] GPU Tracking...\n[codecarbon INFO @ 15:05:47] No GPU found.\n[codecarbon INFO @ 15:05:47] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:05:47] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:05:49] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:05:49] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:49] >>> Tracker's metadata:\n[codecarbon INFO @ 15:05:49]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:05:49]   Python version: 3.8.10\n[codecarbon INFO @ 15:05:49]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:05:49]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:05:49]   CPU count: 16\n[codecarbon INFO @ 15:05:49]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:49]   GPU count: None\n[codecarbon INFO @ 15:05:49]   GPU model: None\n[codecarbon INFO @ 15:05:53] Energy consumed for RAM : 0.000004 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:05:53] Energy consumed for all CPUs : 0.000007 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:05:53] 0.000010 kWh of electricity used since the beginning.\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Define context and question, and tokenize them\ncontext = reviews[1]\nprint(f\"Context:\\n{context}\")\nquestion = \"What did he like about the brand?\"\ninputs = tokenizer(question, context, return_tensors=\"pt\")\n\nemissions = tracker.stop() ","metadata":{"executionCancelledAt":null,"executionTime":4422,"lastExecutedAt":1714662359972,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Define context and question, and tokenize them\ncontext = reviews[1]\nprint(f\"Context:\\n{context}\")\nquestion = \"What did he like about the brand?\"\ninputs = tokenizer(question, context, return_tensors=\"pt\")\n\nemissions = tracker.stop() ","outputsMetadata":{"0":{"height":416,"type":"stream"},"1":{"height":206,"type":"stream"}}},"id":"3cf75ea4-ae1d-4f4a-9bdb-41f65fd16e8f","cell_type":"code","execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:05:55] [setup] RAM Tracking...\n[codecarbon INFO @ 15:05:55] [setup] GPU Tracking...\n[codecarbon INFO @ 15:05:55] No GPU found.\n[codecarbon INFO @ 15:05:55] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:05:55] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:05:56] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:05:56] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:56] >>> Tracker's metadata:\n[codecarbon INFO @ 15:05:56]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:05:56]   Python version: 3.8.10\n[codecarbon INFO @ 15:05:56]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:05:56]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:05:56]   CPU count: 16\n[codecarbon INFO @ 15:05:56]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:05:56]   GPU count: None\n[codecarbon INFO @ 15:05:56]   GPU model: None\n[codecarbon INFO @ 15:05:59] Energy consumed for RAM : 0.000000 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:05:59] Energy consumed for all CPUs : 0.000000 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:05:59] 0.000000 kWh of electricity used since the beginning.\n"},{"output_type":"stream","name":"stdout","text":"Context:\nThe car is fine. It's a bit loud and not very powerful. On one hand, compared to its peers, the interior is well-built. The transmission failed a few years ago, and the dealer replaced it under warranty with no issues. Now, about 60k miles later, the transmission is failing again. It sounds like a truck, and the issues are well-documented. The dealer tells me it is normal, refusing to do anything to resolve the issue. After owning the car for 4 years, there are many other vehicles I would purchase over this one. Initially, I really liked what the brand is about: ride quality, reliability, etc. But I will not purchase another one. Despite these concerns, I must say, the level of comfort in the car has always been satisfactory, but not worth the rest of issues found.\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Perform inference and extract answer from raw outputs\nwith torch.no_grad():\n    \n#The model outputs the logits (scores) that represent the likelihood of each token being the start and end of the answer.\n  outputs = model(**inputs) \n \n#Identify the position of the highest score in start_logits to determine where the answer starts and ends.\nstart_idx = torch.argmax(outputs.start_logits) \nend_idx = torch.argmax(outputs.end_logits) + 1 \n\n# Extract the token IDs of the answer span based on the start and end indices.\nanswer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n\n#Decode the token IDs back into the text of the answer.\nanswer = tokenizer.decode(answer_span)\nprint(\"Answer: \", answer)\nemissions = tracker.stop() \n","metadata":{"executionCancelledAt":null,"executionTime":4727,"lastExecutedAt":1714662372543,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Perform inference and extract answer from raw outputs\nwith torch.no_grad():\n    \n#The model outputs the logits (scores) that represent the likelihood of each token being the start and end of the answer.\n  outputs = model(**inputs) \n \n#Identify the position of the highest score in start_logits to determine where the answer starts and ends.\nstart_idx = torch.argmax(outputs.start_logits) \nend_idx = torch.argmax(outputs.end_logits) + 1 \n\n# Extract the token IDs of the answer span based on the start and end indices.\nanswer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n\n#Decode the token IDs back into the text of the answer.\nanswer = tokenizer.decode(answer_span)\nprint(\"Answer: \", answer)\nemissions = tracker.stop() \n","outputsMetadata":{"0":{"height":395,"type":"stream"},"1":{"height":38,"type":"stream"}}},"id":"693a1866-5a2c-4be9-9eeb-584d6a0e785e","cell_type":"code","execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:06:07] [setup] RAM Tracking...\n[codecarbon INFO @ 15:06:07] [setup] GPU Tracking...\n[codecarbon INFO @ 15:06:07] No GPU found.\n[codecarbon INFO @ 15:06:07] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:06:07] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:06:09] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:06:09] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:06:09] >>> Tracker's metadata:\n[codecarbon INFO @ 15:06:09]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:06:09]   Python version: 3.8.10\n[codecarbon INFO @ 15:06:09]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:06:09]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:06:09]   CPU count: 16\n[codecarbon INFO @ 15:06:09]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:06:09]   GPU count: None\n[codecarbon INFO @ 15:06:09]   GPU model: None\n[codecarbon INFO @ 15:06:12] Energy consumed for RAM : 0.000002 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:06:12] Energy consumed for all CPUs : 0.000004 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:06:12] 0.000007 kWh of electricity used since the beginning.\n"},{"output_type":"stream","name":"stdout","text":"Answer:  ride quality, reliability\n"}]},{"source":"It indicates that the reviewer values both the physical comfort and driving experience provided by the car, as well as its ability to operate without issues consistently","metadata":{},"id":"4791f84a-d67f-4986-adc2-8d3a67366e18","cell_type":"markdown"},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Get original text to summarize upon car review \ntext_to_summarize = reviews[-1] \nprint(f\"Original text:\\n{text_to_summarize}\")\nemissions = tracker.stop() \n","metadata":{"executionCancelledAt":null,"executionTime":4337,"lastExecutedAt":1714662376880,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Get original text to summarize upon car review \ntext_to_summarize = reviews[-1] \nprint(f\"Original text:\\n{text_to_summarize}\")\nemissions = tracker.stop() \n","outputsMetadata":{"0":{"height":458,"type":"stream"},"1":{"height":269,"type":"stream"}}},"id":"456c2d24-3fb0-46e7-9b7d-6aded1ffb0ed","cell_type":"code","execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:06:12] [setup] RAM Tracking...\n[codecarbon INFO @ 15:06:12] [setup] GPU Tracking...\n[codecarbon INFO @ 15:06:12] No GPU found.\n[codecarbon INFO @ 15:06:12] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:06:12] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:06:13] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:06:13] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:06:13] >>> Tracker's metadata:\n[codecarbon INFO @ 15:06:13]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:06:13]   Python version: 3.8.10\n[codecarbon INFO @ 15:06:13]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:06:13]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:06:13]   CPU count: 16\n[codecarbon INFO @ 15:06:13]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:06:13]   GPU count: None\n[codecarbon INFO @ 15:06:13]   GPU model: None\n[codecarbon INFO @ 15:06:16] Energy consumed for RAM : 0.000000 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:06:16] Energy consumed for all CPUs : 0.000000 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:06:16] 0.000000 kWh of electricity used since the beginning.\n"},{"output_type":"stream","name":"stdout","text":"Original text:\nI've been dreaming of owning an SUV for quite a while, but I've been driving cars that were already paid for during an extended period. I ultimately made the decision to transition to a brand-new car, which, of course, involved taking on new payments. However, given that I don't drive extensively, I was inclined to avoid a substantial financial commitment. The Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment; the financial arrangement is quite reasonable. Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more. I am VERY satisfied overall. I find myself needing to exercise extra caution when making lane changes, particularly owing to the blind spots resulting from the small side windows situated towards the rear of the vehicle. To address this concern, I am actively engaged in making adjustments to my mirrors and consciously reducing the frequency of lane changes. The engine delivers strong performance, and the ride is really smooth.\n"}]},{"source":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Load summarization pipeline and perform inference\n#T5-small-booksum summarization model allows for leveraging advanced AI tools to automate the summarization process\n#Ensures consistency and scalability in handling customer reviews\nmodel_name = \"cnicu/t5-small-booksum\"\nsummarizer = pipeline(\"summarization\", model=model_name)\noutputs = summarizer(text_to_summarize, max_length=53)\nsummarized_text = outputs[0]['summary_text']\nprint(f\"Summarized text:\\n{summarized_text}\")\nemissions = tracker.stop() ","metadata":{"executionCancelledAt":null,"executionTime":11270,"lastExecutedAt":1714662394625,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the emissions tracker\ntracker = EmissionsTracker()\ntracker.start()\n# Load summarization pipeline and perform inference\n#T5-small-booksum summarization model allows for leveraging advanced AI tools to automate the summarization process\n#Ensures consistency and scalability in handling customer reviews\nmodel_name = \"cnicu/t5-small-booksum\"\nsummarizer = pipeline(\"summarization\", model=model_name)\noutputs = summarizer(text_to_summarize, max_length=53)\nsummarized_text = outputs[0]['summary_text']\nprint(f\"Summarized text:\\n{summarized_text}\")\nemissions = tracker.stop() ","outputsMetadata":{"0":{"height":395,"type":"stream"},"1":{"height":101,"type":"stream"},"6":{"height":101,"type":"stream"},"7":{"height":80,"type":"stream"},"8":{"height":101,"type":"stream"}}},"id":"2905ddac-4752-45a7-a8b6-58fa0e91b3a0","cell_type":"code","execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":"[codecarbon INFO @ 15:06:23] [setup] RAM Tracking...\n[codecarbon INFO @ 15:06:23] [setup] GPU Tracking...\n[codecarbon INFO @ 15:06:23] No GPU found.\n[codecarbon INFO @ 15:06:23] [setup] CPU Tracking...\n[codecarbon WARNING @ 15:06:23] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon WARNING @ 15:06:24] We saw that you have a AMD EPYC 7R13 Processor but we don't know it. Please contact us.\n[codecarbon INFO @ 15:06:24] CPU Model on constant consumption mode: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:06:24] >>> Tracker's metadata:\n[codecarbon INFO @ 15:06:24]   Platform system: Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29\n[codecarbon INFO @ 15:06:24]   Python version: 3.8.10\n[codecarbon INFO @ 15:06:24]   CodeCarbon version: 2.3.5\n[codecarbon INFO @ 15:06:24]   Available RAM : 61.460 GB\n[codecarbon INFO @ 15:06:24]   CPU count: 16\n[codecarbon INFO @ 15:06:24]   CPU model: AMD EPYC 7R13 Processor\n[codecarbon INFO @ 15:06:24]   GPU count: None\n[codecarbon INFO @ 15:06:24]   GPU model: None\n[codecarbon INFO @ 15:06:34] Energy consumed for RAM : 0.000044 kWh. RAM Power : 23.047675609588623 W\n[codecarbon INFO @ 15:06:34] Energy consumed for all CPUs : 0.000082 kWh. Total CPU Power : 42.5 W\n[codecarbon INFO @ 15:06:34] 0.000126 kWh of electricity used since the beginning.\n"},{"output_type":"stream","name":"stdout","text":"Summarized text:\nthe Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment; the financial arrangement is quite reasonable. I have hauled 12 bags of mulch in the back with the seats down and could have held more.\n"}]},{"source":"# Load emissions data\ndata_path = 'emissions.csv'\ndf_Carbon = pd.read_csv(data_path)\n","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1714662394674,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load emissions data\ndata_path = 'emissions.csv'\ndf_Carbon = pd.read_csv(data_path)\n"},"id":"c32d78be-dffa-4182-815c-184488573bcf","cell_type":"code","execution_count":45,"outputs":[]},{"source":"print(df_Carbon.columns)\n","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1714662394728,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(df_Carbon.columns)\n","outputsMetadata":{"0":{"height":332,"type":"stream"}}},"id":"6efa2d05-9350-4d69-adac-f10cf4336bb2","cell_type":"code","execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":"Index(['timestamp', 'project_name', 'run_id', 'duration', 'emissions',\n       'emissions_rate', 'cpu_power', 'gpu_power', 'ram_power', 'cpu_energy',\n       'gpu_energy', 'ram_energy', 'energy_consumed', 'country_name',\n       'country_iso_code', 'region', 'cloud_provider', 'cloud_region', 'os',\n       'python_version', 'codecarbon_version', 'cpu_count', 'cpu_model',\n       'gpu_count', 'gpu_model', 'longitude', 'latitude', 'ram_total_size',\n       'tracking_mode', 'on_cloud', 'pue'],\n      dtype='object')\n"}]},{"source":"df_Carbon.head()","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1714662395761,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"df_Carbon.head()","outputsMetadata":{"0":{"height":194,"type":"dataFrame"}}},"id":"7a34a2f9-d4ad-45de-b89e-9532321a417f","cell_type":"code","execution_count":47,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"timestamp","type":"string"},{"name":"project_name","type":"string"},{"name":"run_id","type":"string"},{"name":"duration","type":"number"},{"name":"emissions","type":"number"},{"name":"emissions_rate","type":"number"},{"name":"cpu_power","type":"number"},{"name":"gpu_power","type":"number"},{"name":"ram_power","type":"number"},{"name":"cpu_energy","type":"number"},{"name":"gpu_energy","type":"integer"},{"name":"ram_energy","type":"number"},{"name":"energy_consumed","type":"number"},{"name":"country_name","type":"string"},{"name":"country_iso_code","type":"string"},{"name":"region","type":"string"},{"name":"cloud_provider","type":"number"},{"name":"cloud_region","type":"number"},{"name":"os","type":"string"},{"name":"python_version","type":"string"},{"name":"codecarbon_version","type":"string"},{"name":"cpu_count","type":"integer"},{"name":"cpu_model","type":"string"},{"name":"gpu_count","type":"number"},{"name":"gpu_model","type":"number"},{"name":"longitude","type":"number"},{"name":"latitude","type":"number"},{"name":"ram_total_size","type":"number"},{"name":"tracking_mode","type":"string"},{"name":"on_cloud","type":"string"},{"name":"pue","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"timestamp":["2024-04-26T02:02:44","2024-04-26T02:03:24","2024-04-26T02:04:00","2024-04-26T02:05:41","2024-04-26T02:05:50"],"project_name":["codecarbon","codecarbon","codecarbon","codecarbon","codecarbon"],"run_id":["1d5bac96-1e1f-40e5-b5da-1c980f47f984","26de6bf5-b19a-43bb-986b-b99f49a9300d","3c6a01e3-afc6-4d1f-8f32-5c9b80a0e2bb","a5a3548e-9f48-4090-b2c7-9c19d4c40fa2","4186af39-2083-4297-80c2-95f97ad3bc88"],"duration":[0.0100662708,0.7598474026,2.8115222454,0.2380874157,0.0027770996],"emissions":[5.67e-8,0.0000050983,0.0000188863,0.0000015914,8.8e-9],"emissions_rate":[0.0000056322,0.0000067096,0.0000067175,0.0000066839,0.0000031637],"cpu_power":[42.5,42.5,42.5,42.5,42.5],"gpu_power":[0,0,0,0,0],"ram_power":[23.0476756096,23.0476756096,23.0476756096,23.0476756096,23.0476756096],"cpu_energy":[1.058e-7,0.0000089597,0.0000331803,0.0000028006,2.09e-8],"gpu_energy":[0,0,0,0,0],"ram_energy":[4.78e-8,0.0000048517,0.0000179835,0.0000015104,2.9e-9],"energy_consumed":[1.536e-7,0.0000138115,0.0000511638,0.0000043111,2.38e-8],"country_name":["United States","United States","United States","United States","United States"],"country_iso_code":["USA","USA","USA","USA","USA"],"region":["virginia","virginia","virginia","virginia","virginia"],"cloud_provider":[null,null,null,null,null],"cloud_region":[null,null,null,null,null],"os":["Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29","Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29","Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29","Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29","Linux-5.10.209-198.858.amzn2.x86_64-x86_64-with-glibc2.29"],"python_version":["3.8.10","3.8.10","3.8.10","3.8.10","3.8.10"],"codecarbon_version":["2.3.5","2.3.5","2.3.5","2.3.5","2.3.5"],"cpu_count":[16,16,16,16,16],"cpu_model":["AMD EPYC 7R13 Processor","AMD EPYC 7R13 Processor","AMD EPYC 7R13 Processor","AMD EPYC 7R13 Processor","AMD EPYC 7R13 Processor"],"gpu_count":[null,null,null,null,null],"gpu_model":[null,null,null,null,null],"longitude":[-77.4903,-77.4903,-77.4903,-77.4903,-77.4903],"latitude":[39.0469,39.0469,39.0469,39.0469,39.0469],"ram_total_size":[61.4604682922,61.4604682922,61.4604682922,61.4604682922,61.4604682922],"tracking_mode":["machine","machine","machine","machine","machine"],"on_cloud":["N","N","N","N","N"],"pue":[1,1,1,1,1]}},"total_rows":5,"truncation_type":null},"text/plain":"             timestamp project_name  ... on_cloud  pue\n0  2024-04-26T02:02:44   codecarbon  ...        N  1.0\n1  2024-04-26T02:03:24   codecarbon  ...        N  1.0\n2  2024-04-26T02:04:00   codecarbon  ...        N  1.0\n3  2024-04-26T02:05:41   codecarbon  ...        N  1.0\n4  2024-04-26T02:05:50   codecarbon  ...        N  1.0\n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>project_name</th>\n      <th>run_id</th>\n      <th>duration</th>\n      <th>emissions</th>\n      <th>emissions_rate</th>\n      <th>cpu_power</th>\n      <th>gpu_power</th>\n      <th>ram_power</th>\n      <th>cpu_energy</th>\n      <th>gpu_energy</th>\n      <th>ram_energy</th>\n      <th>energy_consumed</th>\n      <th>country_name</th>\n      <th>country_iso_code</th>\n      <th>region</th>\n      <th>cloud_provider</th>\n      <th>cloud_region</th>\n      <th>os</th>\n      <th>python_version</th>\n      <th>codecarbon_version</th>\n      <th>cpu_count</th>\n      <th>cpu_model</th>\n      <th>gpu_count</th>\n      <th>gpu_model</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>ram_total_size</th>\n      <th>tracking_mode</th>\n      <th>on_cloud</th>\n      <th>pue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-04-26T02:02:44</td>\n      <td>codecarbon</td>\n      <td>1d5bac96-1e1f-40e5-b5da-1c980f47f984</td>\n      <td>0.010066</td>\n      <td>5.669503e-08</td>\n      <td>0.000006</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>1.057751e-07</td>\n      <td>0</td>\n      <td>4.781408e-08</td>\n      <td>1.535891e-07</td>\n      <td>United States</td>\n      <td>USA</td>\n      <td>virginia</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Linux-5.10.209-198.858.amzn2.x86_64-x86_64-wit...</td>\n      <td>3.8.10</td>\n      <td>2.3.5</td>\n      <td>16</td>\n      <td>AMD EPYC 7R13 Processor</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>39.0469</td>\n      <td>61.460468</td>\n      <td>machine</td>\n      <td>N</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-04-26T02:03:24</td>\n      <td>codecarbon</td>\n      <td>26de6bf5-b19a-43bb-986b-b99f49a9300d</td>\n      <td>0.759847</td>\n      <td>5.098288e-06</td>\n      <td>0.000007</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>8.959733e-06</td>\n      <td>0</td>\n      <td>4.851736e-06</td>\n      <td>1.381147e-05</td>\n      <td>United States</td>\n      <td>USA</td>\n      <td>virginia</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Linux-5.10.209-198.858.amzn2.x86_64-x86_64-wit...</td>\n      <td>3.8.10</td>\n      <td>2.3.5</td>\n      <td>16</td>\n      <td>AMD EPYC 7R13 Processor</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>39.0469</td>\n      <td>61.460468</td>\n      <td>machine</td>\n      <td>N</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-04-26T02:04:00</td>\n      <td>codecarbon</td>\n      <td>3c6a01e3-afc6-4d1f-8f32-5c9b80a0e2bb</td>\n      <td>2.811522</td>\n      <td>1.888632e-05</td>\n      <td>0.000007</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>3.318028e-05</td>\n      <td>0</td>\n      <td>1.798353e-05</td>\n      <td>5.116382e-05</td>\n      <td>United States</td>\n      <td>USA</td>\n      <td>virginia</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Linux-5.10.209-198.858.amzn2.x86_64-x86_64-wit...</td>\n      <td>3.8.10</td>\n      <td>2.3.5</td>\n      <td>16</td>\n      <td>AMD EPYC 7R13 Processor</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>39.0469</td>\n      <td>61.460468</td>\n      <td>machine</td>\n      <td>N</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-04-26T02:05:41</td>\n      <td>codecarbon</td>\n      <td>a5a3548e-9f48-4090-b2c7-9c19d4c40fa2</td>\n      <td>0.238087</td>\n      <td>1.591358e-06</td>\n      <td>0.000007</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>2.800616e-06</td>\n      <td>0</td>\n      <td>1.510438e-06</td>\n      <td>4.311054e-06</td>\n      <td>United States</td>\n      <td>USA</td>\n      <td>virginia</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Linux-5.10.209-198.858.amzn2.x86_64-x86_64-wit...</td>\n      <td>3.8.10</td>\n      <td>2.3.5</td>\n      <td>16</td>\n      <td>AMD EPYC 7R13 Processor</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>39.0469</td>\n      <td>61.460468</td>\n      <td>machine</td>\n      <td>N</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-04-26T02:05:50</td>\n      <td>codecarbon</td>\n      <td>4186af39-2083-4297-80c2-95f97ad3bc88</td>\n      <td>0.002777</td>\n      <td>8.785861e-09</td>\n      <td>0.000003</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>2.089043e-08</td>\n      <td>0</td>\n      <td>2.910820e-09</td>\n      <td>2.380126e-08</td>\n      <td>United States</td>\n      <td>USA</td>\n      <td>virginia</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Linux-5.10.209-198.858.amzn2.x86_64-x86_64-wit...</td>\n      <td>3.8.10</td>\n      <td>2.3.5</td>\n      <td>16</td>\n      <td>AMD EPYC 7R13 Processor</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>39.0469</td>\n      <td>61.460468</td>\n      <td>machine</td>\n      <td>N</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":47}]},{"source":"df_Carbon.info()","metadata":{"executionCancelledAt":null,"executionTime":17,"lastExecutedAt":1714662399756,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"df_Carbon.info()","outputsMetadata":{"0":{"height":475,"type":"stream"}}},"id":"89c74b4b-61f0-4fbb-8447-16db0423fff6","cell_type":"code","execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 120 entries, 0 to 119\nData columns (total 31 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   timestamp           120 non-null    object \n 1   project_name        120 non-null    object \n 2   run_id              120 non-null    object \n 3   duration            120 non-null    float64\n 4   emissions           120 non-null    float64\n 5   emissions_rate      120 non-null    float64\n 6   cpu_power           120 non-null    float64\n 7   gpu_power           120 non-null    float64\n 8   ram_power           120 non-null    float64\n 9   cpu_energy          120 non-null    float64\n 10  gpu_energy          120 non-null    int64  \n 11  ram_energy          120 non-null    float64\n 12  energy_consumed     120 non-null    float64\n 13  country_name        120 non-null    object \n 14  country_iso_code    120 non-null    object \n 15  region              120 non-null    object \n 16  cloud_provider      0 non-null      float64\n 17  cloud_region        0 non-null      float64\n 18  os                  120 non-null    object \n 19  python_version      120 non-null    object \n 20  codecarbon_version  120 non-null    object \n 21  cpu_count           120 non-null    int64  \n 22  cpu_model           120 non-null    object \n 23  gpu_count           0 non-null      float64\n 24  gpu_model           0 non-null      float64\n 25  longitude           120 non-null    float64\n 26  latitude            120 non-null    float64\n 27  ram_total_size      120 non-null    float64\n 28  tracking_mode       120 non-null    object \n 29  on_cloud            120 non-null    object \n 30  pue                 120 non-null    float64\ndtypes: float64(17), int64(2), object(12)\nmemory usage: 29.2+ KB\n"}]},{"source":"df_Carbon.describe()","metadata":{"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"line","version":"v1","x":{"field":"duration","type":"number"},"y":{"field":"energy_consumed","type":"number"}},"executionCancelledAt":null,"executionTime":68,"lastExecutedAt":1714662404454,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"df_Carbon.describe()","outputsMetadata":{"0":{"height":269,"type":"dataFrame"}},"visualizeDataframe":false},"id":"dadfe8b9-deb7-4385-a477-10066bac2248","cell_type":"code","execution_count":49,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"string"},{"name":"duration","type":"number"},{"name":"emissions","type":"number"},{"name":"emissions_rate","type":"number"},{"name":"cpu_power","type":"number"},{"name":"gpu_power","type":"number"},{"name":"ram_power","type":"number"},{"name":"cpu_energy","type":"number"},{"name":"gpu_energy","type":"number"},{"name":"ram_energy","type":"number"},{"name":"energy_consumed","type":"number"},{"name":"cloud_provider","type":"number"},{"name":"cloud_region","type":"number"},{"name":"cpu_count","type":"number"},{"name":"gpu_count","type":"number"},{"name":"gpu_model","type":"number"},{"name":"longitude","type":"number"},{"name":"latitude","type":"number"},{"name":"ram_total_size","type":"number"},{"name":"pue","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":["count","mean","std","min","25%","50%","75%","max"],"duration":[120,4.4407042921,11.9132056623,0.0025570393,0.0075719953,0.3963027,4.0756244063,78.3141634464],"emissions":[120,0.0000298243,0.0000800385,8.4e-9,4.1e-8,0.0000026535,0.0000273819,0.0005263268],"emissions_rate":[120,0.0000058371,0.0000013295,0.0000027625,0.00000546,0.0000066953,0.0000067179,0.0000067207],"cpu_power":[120,42.5,0,42.5,42.5,42.5,42.5,42.5],"gpu_power":[120,0,0,0,0,0,0,0],"ram_power":[120,23.0476756096,0,23.0476756096,23.0476756096,23.0476756096,23.0476756096,23.0476756096],"cpu_energy":[120,0.0000524031,0.0001406294,1.98e-8,7.78e-8,0.0000046669,0.0000481027,0.0009245077],"gpu_energy":[120,0,0,0,0,0,0,0],"ram_energy":[120,0.0000283921,0.0000761983,2.4e-9,3.32e-8,0.0000025216,0.000026076,0.000501333],"energy_consumed":[120,0.0000807953,0.0002168276,2.28e-8,1.11e-7,0.0000071885,0.0000741787,0.0014258406],"cloud_provider":[0,null,null,null,null,null,null,null],"cloud_region":[0,null,null,null,null,null,null,null],"cpu_count":[120,16,0,16,16,16,16,16],"gpu_count":[0,null,null,null,null,null,null,null],"gpu_model":[0,null,null,null,null,null,null,null],"longitude":[120,-77.4903,0,-77.4903,-77.4903,-77.4903,-77.4903,-77.4903],"latitude":[120,39.0469,0,39.0469,39.0469,39.0469,39.0469,39.0469],"ram_total_size":[120,61.4604682922,0,61.4604682922,61.4604682922,61.4604682922,61.4604682922,61.4604682922],"pue":[120,1,0,1,1,1,1,1]}},"total_rows":8,"truncation_type":null},"text/plain":"         duration     emissions  ...  ram_total_size    pue\ncount  120.000000  1.200000e+02  ...      120.000000  120.0\nmean     4.440704  2.982432e-05  ...       61.460468    1.0\nstd     11.913206  8.003851e-05  ...        0.000000    0.0\nmin      0.002557  8.400040e-09  ...       61.460468    1.0\n25%      0.007572  4.097508e-08  ...       61.460468    1.0\n50%      0.396303  2.653528e-06  ...       61.460468    1.0\n75%      4.075624  2.738191e-05  ...       61.460468    1.0\nmax     78.314163  5.263268e-04  ...       61.460468    1.0\n\n[8 rows x 19 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>emissions</th>\n      <th>emissions_rate</th>\n      <th>cpu_power</th>\n      <th>gpu_power</th>\n      <th>ram_power</th>\n      <th>cpu_energy</th>\n      <th>gpu_energy</th>\n      <th>ram_energy</th>\n      <th>energy_consumed</th>\n      <th>cloud_provider</th>\n      <th>cloud_region</th>\n      <th>cpu_count</th>\n      <th>gpu_count</th>\n      <th>gpu_model</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>ram_total_size</th>\n      <th>pue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>120.000000</td>\n      <td>1.200000e+02</td>\n      <td>120.000000</td>\n      <td>120.0</td>\n      <td>120.0</td>\n      <td>120.000000</td>\n      <td>1.200000e+02</td>\n      <td>120.0</td>\n      <td>1.200000e+02</td>\n      <td>1.200000e+02</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>120.0000</td>\n      <td>1.200000e+02</td>\n      <td>120.000000</td>\n      <td>120.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.440704</td>\n      <td>2.982432e-05</td>\n      <td>0.000006</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>5.240314e-05</td>\n      <td>0.0</td>\n      <td>2.839214e-05</td>\n      <td>8.079529e-05</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>3.904690e+01</td>\n      <td>61.460468</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>11.913206</td>\n      <td>8.003851e-05</td>\n      <td>0.000001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.406294e-04</td>\n      <td>0.0</td>\n      <td>7.619827e-05</td>\n      <td>2.168276e-04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0000</td>\n      <td>7.135220e-15</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.002557</td>\n      <td>8.400040e-09</td>\n      <td>0.000003</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>1.976738e-08</td>\n      <td>0.0</td>\n      <td>2.405586e-09</td>\n      <td>2.275605e-08</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>3.904690e+01</td>\n      <td>61.460468</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.007572</td>\n      <td>4.097508e-08</td>\n      <td>0.000005</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>7.780012e-08</td>\n      <td>0.0</td>\n      <td>3.322907e-08</td>\n      <td>1.110032e-07</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>3.904690e+01</td>\n      <td>61.460468</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.396303</td>\n      <td>2.653528e-06</td>\n      <td>0.000007</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>4.666924e-06</td>\n      <td>0.0</td>\n      <td>2.521592e-06</td>\n      <td>7.188515e-06</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>3.904690e+01</td>\n      <td>61.460468</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.075624</td>\n      <td>2.738191e-05</td>\n      <td>0.000007</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>4.810271e-05</td>\n      <td>0.0</td>\n      <td>2.607601e-05</td>\n      <td>7.417871e-05</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>3.904690e+01</td>\n      <td>61.460468</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>78.314163</td>\n      <td>5.263268e-04</td>\n      <td>0.000007</td>\n      <td>42.5</td>\n      <td>0.0</td>\n      <td>23.047676</td>\n      <td>9.245077e-04</td>\n      <td>0.0</td>\n      <td>5.013330e-04</td>\n      <td>1.425841e-03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-77.4903</td>\n      <td>3.904690e+01</td>\n      <td>61.460468</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":49}]},{"source":"import plotly.express as px\n\n# Assume df_Carbon is your DataFrame with the required data\nfig = px.line(df_Carbon, x='timestamp', y='emissions', title='Carbon Emissions Over Time',\n              labels={'timestamp': 'Time', 'emissions': 'CO2 Emissions (grams)'},\n              template='plotly_dark')\n\n# Update layout with x-axis title, y-axis title, and modify x-axis for range slider and buttons\nfig.update_layout(\n    xaxis_title='Time',\n    yaxis_title='Carbon Emissions (grams)',\n    xaxis=dict(\n        rangeslider=dict(visible=True),\n        rangeselector=dict(\n            buttons=list([\n                dict(count=30, label=\"30s\", step=\"second\", stepmode=\"backward\"),\n                dict(count=2, label=\"2m\", step=\"minute\", stepmode=\"backward\"),\n                dict(count=5, label=\"5m\", step=\"minute\", stepmode=\"backward\"),\n                dict(count=10, label=\"10m\", step=\"minute\", stepmode=\"backward\"),\n                dict(count=30, label=\"30m\", step=\"minute\", stepmode=\"backward\"),\n                dict(count=1, label=\"1h\", step=\"hour\", stepmode=\"backward\"),\n                dict(step=\"all\")\n            ])\n        ),\n        type='date'\n    ),\n    yaxis=dict(type='linear')\n)\n\nfig.show()\n","metadata":{"executionCancelledAt":null,"executionTime":72,"lastExecutedAt":1714662527073,"lastExecutedByKernel":"5b9b4d97-b211-4025-b022-050c44031aca","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import plotly.express as px\n\n# Assume df_Carbon is your DataFrame with the required data\nfig = px.line(df_Carbon, x='timestamp', y='emissions', title='Carbon Emissions Over Time',\n              labels={'timestamp': 'Time', 'emissions': 'CO2 Emissions (grams)'},\n              template='plotly_dark')\n\n# Update layout with x-axis title, y-axis title, and modify x-axis for range slider and buttons\nfig.update_layout(\n    xaxis_title='Time',\n    yaxis_title='Carbon Emissions (grams)',\n    xaxis=dict(\n        rangeslider=dict(visible=True),\n        rangeselector=dict(\n            buttons=list([\n                dict(count=30, label=\"30s\", step=\"second\", stepmode=\"backward\"),\n                dict(count=2, label=\"2m\", step=\"minute\", stepmode=\"backward\"),\n                dict(count=5, label=\"5m\", step=\"minute\", stepmode=\"backward\"),\n                dict(count=10, label=\"10m\", step=\"minute\", stepmode=\"backward\"),\n                dict(count=30, label=\"30m\", step=\"minute\", stepmode=\"backward\"),\n                dict(count=1, label=\"1h\", step=\"hour\", stepmode=\"backward\"),\n                dict(step=\"all\")\n            ])\n        ),\n        type='date'\n    ),\n    yaxis=dict(type='linear')\n)\n\nfig.show()\n","outputsMetadata":{"0":{"height":467,"type":"plotly"}}},"id":"c6966f7d-f2d7-43e6-be2d-e0b8a32a3257","cell_type":"code","execution_count":51,"outputs":[{"output_type":"display_data","data":{"application/vnd.plotly.v1+json":{"data":[{"hovertemplate":"Time=%{x}<br>CO2 Emissions (grams)=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":["2024-04-26T02:02:44","2024-04-26T02:03:24","2024-04-26T02:04:00","2024-04-26T02:05:41","2024-04-26T02:05:50","2024-04-26T02:05:57","2024-04-26T02:06:30","2024-04-26T02:06:36","2024-04-26T02:07:11","2024-04-26T02:07:19","2024-04-26T02:07:27","2024-04-26T02:07:33","2024-04-26T02:07:46","2024-04-26T02:07:52","2024-04-26T02:08:10","2024-04-27T15:34:41","2024-04-27T15:34:54","2024-04-27T15:35:02","2024-04-27T15:35:07","2024-04-27T15:35:11","2024-04-27T15:35:15","2024-04-27T15:35:30","2024-04-27T15:35:34","2024-04-27T15:35:39","2024-04-27T15:35:43","2024-04-27T15:35:50","2024-04-27T15:35:54","2024-04-27T15:35:59","2024-04-27T15:36:03","2024-04-27T15:36:17","2024-04-27T15:43:44","2024-04-27T15:46:05","2024-04-27T15:46:19","2024-04-27T16:12:33","2024-04-27T16:12:47","2024-04-27T16:12:55","2024-04-27T16:13:00","2024-04-27T16:13:04","2024-04-27T16:13:08","2024-04-27T16:14:10","2024-04-27T16:14:15","2024-04-27T16:14:19","2024-04-27T16:14:24","2024-04-27T16:14:31","2024-04-27T16:14:35","2024-04-27T16:14:40","2024-04-27T16:14:44","2024-04-27T16:14:59","2024-04-27T16:21:22","2024-04-27T16:22:39","2024-04-27T16:22:44","2024-04-27T16:23:34","2024-04-27T16:24:48","2024-04-27T16:26:07","2024-04-27T16:26:54","2024-04-27T16:27:25","2024-04-27T16:27:54","2024-04-27T16:27:59","2024-04-27T16:28:13","2024-04-27T16:28:39","2024-04-27T16:28:44","2024-04-27T16:34:12","2024-04-27T16:34:26","2024-04-27T16:42:12","2024-04-27T16:43:46","2024-04-27T16:44:13","2024-04-27T16:44:17","2024-04-27T16:44:43","2024-04-27T16:49:04","2024-04-27T17:11:46","2024-04-27T17:11:51","2024-04-27T17:11:59","2024-04-27T17:12:04","2024-04-27T17:12:08","2024-04-27T17:12:13","2024-04-27T17:12:23","2024-04-27T17:12:27","2024-04-27T17:12:32","2024-04-27T17:12:37","2024-04-27T17:12:42","2024-04-27T17:12:46","2024-04-27T17:12:51","2024-04-27T17:12:55","2024-04-27T17:13:06","2024-05-02T14:57:33","2024-05-02T14:57:47","2024-05-02T14:57:55","2024-05-02T14:58:00","2024-05-02T14:58:04","2024-05-02T14:58:09","2024-05-02T14:58:23","2024-05-02T14:58:28","2024-05-02T14:58:33","2024-05-02T14:58:38","2024-05-02T14:58:45","2024-05-02T14:58:49","2024-05-02T14:58:54","2024-05-02T14:58:58","2024-05-02T14:59:13","2024-05-02T15:02:37","2024-05-02T15:02:45","2024-05-02T15:02:52","2024-05-02T15:03:07","2024-05-02T15:03:15","2024-05-02T15:04:18","2024-05-02T15:04:47","2024-05-02T15:04:58","2024-05-02T15:05:02","2024-05-02T15:05:09","2024-05-02T15:05:15","2024-05-02T15:05:27","2024-05-02T15:05:31","2024-05-02T15:05:36","2024-05-02T15:05:40","2024-05-02T15:05:53","2024-05-02T15:05:59","2024-05-02T15:06:04","2024-05-02T15:06:12","2024-05-02T15:06:16","2024-05-02T15:06:34"],"xaxis":"x","y":[5.66950335793828e-8,0.000005098288302598065,0.0000188863242234614,0.0000015913581682846196,8.785861477050531e-9,7.464334688093528e-8,0.000039543677659586144,4.0584318625212015e-8,0.000001668771005331917,8.576195504450144e-9,0.0000035520583919435644,1.5165790769856517e-8,0.000002592704498794292,9.263145155544457e-9,0.000045893886227055096,6.435344585936779e-8,0.000059598337562849954,0.00002204836269798025,0.000003897855327250365,9.629764038648788e-9,9.293701353189194e-8,0.0000675016879348248,4.717528008695656e-8,0.000002438332164380456,9.799610041813215e-9,0.00001686061581259457,1.4109822151788617e-8,0.0000019967898087266352,1.0153278908706975e-8,0.00006599964081364099,0.0003580136157707,0.0003619801953382,2.4900265463938666e-8,6.732382842789714e-8,0.00006611180608706421,0.00002127527507570394,0.000004292833233063427,8.431498601290967e-9,1.0423180958430029e-7,0.0003839207415342,5.1266981396221686e-8,0.0000027115406256019373,1.0874823582894345e-8,0.000016908261551894825,1.6698020352924693e-8,0.0000023102290343591246,1.0007930668696844e-8,0.00007072832065671916,0.00004079468427614229,0.0003233063920864,0.000002822742085906973,0.000041306733330384936,0.0000031999551227798013,0.00004594495352827719,0.00005300412917509157,0.0000030848667085483105,0.00003957048147137244,4.110533434251748e-8,0.000002595515674157616,0.0000406183657373973,0.000003183011498274784,0.00004189525712373212,0.000003035274293314146,0.00004101667564635649,0.0000034636333486741023,0.0000412993649052712,0.000002834226426611325,8.426889972233242e-9,0.000003759088482701068,5.8639766676777226e-8,0.00000600573714160796,0.00002332799088128548,0.000002234872970550852,8.879749004202228e-9,7.168673688020827e-8,0.00004026546836403517,4.135742765609256e-8,0.0000035374318915317224,9.025778054905817e-9,0.000003600175462444992,1.609310712039231e-8,0.0000025247611784553195,9.408278982117484e-9,0.00004653586589516007,9.636128752246793e-8,0.00006404693645835607,0.00002295085794309633,0.000004252598528606654,8.400040342947817e-9,9.659592988287928e-8,0.00007043111480817808,5.8419084374579174e-8,0.000004138025811705556,9.527854679069564e-9,0.0000176412541164901,1.430663057797574e-8,0.0000022055422625041367,1.0685913021360033e-8,0.00007062166863461468,1.5898732300186756e-8,0.000002212420257809529,1.0640188348250602e-8,0.0000471157063548138,0.0001035985836051,0.0005263267972207,0.0000055069911182952055,0.00002281434073611821,0.0000015565666608475524,8.963068825889e-9,7.009015656911896e-8,0.00004070441632115757,4.028694978934168e-8,0.00000366986191396911,8.744114946769282e-9,0.000003783470229493729,1.7661961931233575e-8,0.000002540366450302242,0.0000025492367822479264,8.798507160843045e-9,0.00004656660008198012],"yaxis":"y","type":"scatter"}],"layout":{"template":{"data":{"barpolar":[{"marker":{"line":{"color":"rgb(17,17,17)","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#f2f5fa"},"error_y":{"color":"#f2f5fa"},"marker":{"line":{"color":"rgb(17,17,17)","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#A2B1C6","gridcolor":"#506784","linecolor":"#506784","minorgridcolor":"#506784","startlinecolor":"#A2B1C6"},"baxis":{"endlinecolor":"#A2B1C6","gridcolor":"#506784","linecolor":"#506784","minorgridcolor":"#506784","startlinecolor":"#A2B1C6"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"line":{"color":"#283442"}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"marker":{"line":{"color":"#283442"}},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#506784"},"line":{"color":"rgb(17,17,17)"}},"header":{"fill":{"color":"#2a3f5f"},"line":{"color":"rgb(17,17,17)"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#f2f5fa","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#f2f5fa"},"geo":{"bgcolor":"rgb(17,17,17)","lakecolor":"rgb(17,17,17)","landcolor":"rgb(17,17,17)","showlakes":true,"showland":true,"subunitcolor":"#506784"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"dark"},"paper_bgcolor":"rgb(17,17,17)","plot_bgcolor":"rgb(17,17,17)","polar":{"angularaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"bgcolor":"rgb(17,17,17)","radialaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"},"yaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"},"zaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"}},"shapedefaults":{"line":{"color":"#f2f5fa"}},"sliderdefaults":{"bgcolor":"#C8D4E3","bordercolor":"rgb(17,17,17)","borderwidth":1,"tickwidth":0},"ternary":{"aaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"baxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"bgcolor":"rgb(17,17,17)","caxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""}},"title":{"x":0.05},"updatemenudefaults":{"bgcolor":"#506784","borderwidth":0},"xaxis":{"automargin":true,"gridcolor":"#283442","linecolor":"#506784","ticks":"","title":{"standoff":15},"zerolinecolor":"#283442","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#283442","linecolor":"#506784","ticks":"","title":{"standoff":15},"zerolinecolor":"#283442","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"Time"},"rangeslider":{"visible":true},"rangeselector":{"buttons":[{"count":30,"label":"30s","step":"second","stepmode":"backward"},{"count":2,"label":"2m","step":"minute","stepmode":"backward"},{"count":5,"label":"5m","step":"minute","stepmode":"backward"},{"count":10,"label":"10m","step":"minute","stepmode":"backward"},{"count":30,"label":"30m","step":"minute","stepmode":"backward"},{"count":1,"label":"1h","step":"hour","stepmode":"backward"},{"step":"all"}]},"type":"date"},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Carbon Emissions (grams)"},"type":"linear"},"legend":{"tracegroupgap":0},"title":{"text":"Carbon Emissions Over Time"}},"config":{"displaylogo":false,"toImageButtonOptions":{"format":"png","filename":"DataLab plot","height":500,"width":700,"scale":2},"plotlyServerURL":"https://plot.ly"}}},"metadata":{}}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}